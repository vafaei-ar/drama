{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "from matplotlib import gridspec\n",
    "import glob\n",
    "import scipy.io as sio\n",
    "import h5py\n",
    "import sys\n",
    "from sklearn.decomposition import PCA,TruncatedSVD,NMF,FastICA,KernelPCA,IncrementalPCA\n",
    "from sklearn import neighbors \n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import IsolationForest\n",
    "import pickle\n",
    "import time\n",
    "from joblib import Parallel, delayed\n",
    "sys.path.insert(0,'../')\n",
    "import outlier_finder as of\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_sig = 1\n",
    "num = 3000\n",
    "n_out = 50\n",
    "\n",
    "sigma = 0.03\n",
    "n1 = 0.02\n",
    "n2 = 0.01\n",
    "n3 = 0.02\n",
    "n4 = 0.01\n",
    "n_ftrs = 100\n",
    "x = np.linspace(0,1,n_ftrs)\n",
    "\n",
    "X_train = []\n",
    "Y_train = []\n",
    "for i in range(n_sig):\n",
    "    for j in range(num):\n",
    "        X_train.append(of.signal(i+1,x,sigma,n1,n2,n3,n4))\n",
    "        Y_train.append(i)\n",
    "        \n",
    "    for j in range(n_out):\n",
    "        sig = of.signal(i+1,x,sigma,n1,n2,n3,n4)\n",
    "        sig = of.event_sig(sig)\n",
    "        X_train.append(sig)\n",
    "        Y_train.append(i+n_sig)\n",
    "        \n",
    "X_train = np.array(X_train).astype(np.float16)\n",
    "Y_train = np.array(Y_train).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "agg_source = of.AgglomerativeClustering(n_clusters=2,\n",
    "                affinity='euclidean', connectivity=None,\n",
    "                compute_full_tree='auto', linkage='ward')\n",
    "\n",
    "def splitter(z_mu):\n",
    "    num = z_mu.shape[0]\n",
    "    n_divide = int(num/4999)+1\n",
    "    y = np.zeros(num)\n",
    "    for inds in np.array_split(np.arange(num), n_divide):\n",
    "        y[inds] = agg_source.fit_predict(z_mu[inds,:])\n",
    "    return y\n",
    "\n",
    "metrics = ['cityblock','L2','L4','expL4','braycurtis',\n",
    "           'canberra','chebyshev','correlation','mahalanobis',\n",
    "           'wL2','wL4','wexpL4']\n",
    "\n",
    "def outliers(X_test,dc,metrics):\n",
    "    nmetrics = ['cityblock','L2','L4','expL4','braycurtis',\n",
    "           'canberra','chebyshev','correlation']\n",
    "    wmetrics = ['wL2','wL4','wexpL4']\n",
    "    \n",
    "    n_test = X_test.shape[0]\n",
    "    n_ftrs = X_test.shape[1]\n",
    "    out_ind = {}\n",
    "    \n",
    "    mean_vec = dc.mean_vector[-1].reshape(-1,n_ftrs)\n",
    "    cov = dc.covariance[-1].reshape(-1,n_ftrs,n_ftrs)\n",
    "    w = np.array([1./np.sqrt(of.clip(np.diag(cv),a_min=1e-4)) for cv in cov])\n",
    "    dense_components = dc.dense_components[-1].reshape(-1,n_ftrs)\n",
    "    mean_components = dc.mean_components[-1].reshape(-1,n_ftrs)\n",
    "    components = dense_components\n",
    "    \n",
    "    if 'mahalanobis' in metrics:\n",
    "        nc = cov.shape[0]\n",
    "        cov_inv = np.zeros(cov.shape)\n",
    "        for i in range(nc):\n",
    "            cov_inv[i] = np.linalg.pinv(cov[i])\n",
    "\n",
    "        distance_test = np.zeros(n_test)\n",
    "        for i in range(n_test):\n",
    "            dst_arr = np.zeros(nc)\n",
    "            for j in range(nc):\n",
    "                vec = (X_test[i]-mean_vec[j]).reshape(n_ftrs,1)\n",
    "                dst_arr[j] = np.matmul(np.matmul(vec.T,cov_inv[j]),vec)\n",
    "\n",
    "            distance_test[i] = np.min(dst_arr)\n",
    "\n",
    "        distance_test[i] = np.min(dst_arr)\n",
    "        out_ind['mahalanobis'] = np.argsort(distance_test)[::-1]\n",
    "            \n",
    "    for metric in metrics:\n",
    "        if metric in nmetrics:\n",
    "            distance_test = of.dist(metric,np.array(components),X_test)\n",
    "            out_ind[metric] = np.argsort(distance_test)[::-1]\n",
    "        elif metric in wmetrics:\n",
    "            distance_test = of.dist(metric,np.array(components),X_test,w)\n",
    "            out_ind[metric] = np.argsort(distance_test)[::-1]\n",
    "    \n",
    "    return out_ind\n",
    "\n",
    "def quick_outlier_analysis(X,y,ns):\n",
    "    \n",
    "    out = {}\n",
    "    n_data,n_ftrs = X.shape\n",
    "    n_out = (y==1).sum()\n",
    "    nn_en = [n_ftrs, n_ftrs//2, 2]\n",
    "    nn_de = [2, n_ftrs//2, n_ftrs]\n",
    "    network_architecture = [nn_en,nn_de]\n",
    "    out['n_data'] = n_data\n",
    "    out['n_out'] = n_out\n",
    "\n",
    "    dim_rs ={'AE':'AE','VAE':'VAE', \n",
    "             'PCA':PCA(n_components=2),\n",
    "             'NMF':NMF(n_components=2), \n",
    "             'FastICA':FastICA(n_components=2)}\n",
    "    \n",
    "    for dim_r, value in dim_rs.iteritems():\n",
    "        if dim_r=='VAE' or dim_r=='AE':\n",
    "            dc = of.decomposer(X, value, network_architecture, splitter)\n",
    "        else:\n",
    "            dc = of.decomposer_gen(X, of.sk_convert(value), splitter)\n",
    "    \n",
    "        for i in range(ns):\n",
    "            print 'ROUND '+str(i)\n",
    "            if dim_r=='VAE' or dim_r=='AE':\n",
    "                dc.split(1,verbose=True,training_epochs=20)\n",
    "            else:\n",
    "                dc.split(1,verbose=True)\n",
    "                \n",
    "            out_ind = outliers(X,dc,metrics)\n",
    "            for metric in metrics:\n",
    "                t_out = y==1\n",
    "                src = of.score(out_ind[metric][:n_out],t_out)\n",
    "                out['recall_'+dim_r+'_'+metric+'_'+str(i)] = src[n_out-1]\n",
    "                out['auc_'+dim_r+'_'+metric+'_'+str(i)] = roc_auc_score(t_out, of.ind2score(out_ind[metric]))\n",
    "                \n",
    "    for nn in [5,10,35]:\n",
    "        lof = neighbors.LocalOutlierFactor(n_neighbors=nn, contamination=(1.*n_out)/n_data)\n",
    "        lof.fit(X)\n",
    "        scores_pred = lof.negative_outlier_factor_\n",
    "        winds = np.argsort(scores_pred)\n",
    "        src = of.score(winds[:n_out],t_out)\n",
    "        out['recall_LOF'+str(nn)] = src[n_out-1]\n",
    "        out['auc_LOF'+str(nn)] = roc_auc_score(t_out, of.ind2score(winds))\n",
    "    \n",
    "    isof = IsolationForest(max_samples='auto', contamination=(1.*n_out)/n_data)\n",
    "    isof.fit(X)\n",
    "    scores_pred = isof.decision_function(X)\n",
    "    winds = np.argsort(scores_pred)\n",
    "    src = of.score(winds[:n_out],t_out)\n",
    "    out['recall_isof'] = src[n_out-1]\n",
    "    out['auc_isof'] = roc_auc_score(t_out, of.ind2score(winds))\n",
    "    \n",
    "    return out\n",
    "\n",
    "def pklread(name):\n",
    "    with open(name,'r') as f:\n",
    "        data = pickle.load(f)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nn_en = [n_ftrs, n_ftrs//2, 2]\n",
    "nn_de = [2, n_ftrs//2, n_ftrs]\n",
    "network_architecture = [nn_en,nn_de]\n",
    "\n",
    "dim_r ={'TSVD':TruncatedSVD(n_components=2), 'PCA':PCA(n_components=2)\n",
    "       ,'NMF':NMF(n_components=2), 'FastICA':FastICA(n_components=2), \n",
    "       'KPCA':KernelPCA(n_components=2),'IPCA':IncrementalPCA(n_components=2)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/real/arrhythmia.mat\n",
      "(452, 274)\n"
     ]
    }
   ],
   "source": [
    "fils = glob.glob('../data/real/*.mat')\n",
    "fils = ['../data/real/arrhythmia.mat']\n",
    "def job(X,y,n_t):\n",
    "    return quick_outlier_analysis(X,y,3)\n",
    "\n",
    "n_try = 3\n",
    "# i=0\n",
    "for i in range(len(fils)):\n",
    "# for i in range(1):\n",
    "    print fils[i]\n",
    "    try:\n",
    "        data = sio.loadmat(fils[i])\n",
    "        X = data['X'].astype(float)\n",
    "        y = data['y']\n",
    "    except:\n",
    "        data = h5py.File(fils[i])\n",
    "        X = np.array(data['X']).T\n",
    "        y = np.array(data['y']).T\n",
    "        \n",
    "    print X.shape\n",
    "        \n",
    "#     xxx= job(X,y,1)\n",
    "        \n",
    "#     b_time = time.time()\n",
    "    \n",
    "#     out = Parallel(n_jobs=int(3)) (delayed(job)(X,y,n_t) for n_t in range(n_try))  \n",
    "            \n",
    "#     print \"Finished in\", time.time()-b_time , \"sec\"\n",
    "        \n",
    "#     add = fils[i][:-4].split('/')[-1]\n",
    "#     with open(add+'.pkl', 'wb') as f:\n",
    "#         pickle.dump(out, f)\n",
    "        \n",
    "#     print '-------------'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def synt_event(i_sig):\n",
    "    main_data = {i_sig:1000}\n",
    "    event_data = {i_sig:50}\n",
    "    sigma = 0.05\n",
    "    n1 = 0.02\n",
    "    n2 = 0.01\n",
    "    n3 = 0.02\n",
    "    n4 = 0.01\n",
    "\n",
    "    n_ftrs = 200\n",
    "    x = np.linspace(0,1,n_ftrs)\n",
    "\n",
    "    X = []\n",
    "    y = []\n",
    "    for key,value in main_data.iteritems():\n",
    "        for _ in range(value):\n",
    "            Xp = of.signal(key,x,sigma,n1,n2,n3,n4)\n",
    "            X.append(Xp)\n",
    "            y.append(key)\n",
    "\n",
    "    for key,value in event_data.iteritems():\n",
    "        for _ in range(value):\n",
    "            Xp = of.signal(key,x,sigma,n1,n2,n3,n4)\n",
    "            Xp = of.event_sig(Xp)\n",
    "            X.append(Xp)\n",
    "            y.append(key+10)\n",
    "            \n",
    "    return np.array(X),np.array(y)\n",
    "\n",
    "def synt_mix(i_sig):\n",
    "    main_data = {i_sig:3000}\n",
    "    sigma = 0.05\n",
    "    n1 = 0.02\n",
    "    n2 = 0.01\n",
    "    n3 = 0.02\n",
    "    n4 = 0.01\n",
    "\n",
    "    n_ftrs = 200\n",
    "    x = np.linspace(0,1,n_ftrs)\n",
    "\n",
    "    X = []\n",
    "    y = []\n",
    "    for key,value in main_data.iteritems():\n",
    "        for _ in range(value):\n",
    "            Xp = of.signal(key,x,sigma,n1,n2,n3,n4)\n",
    "            X.append(Xp)\n",
    "            y.append(key)\n",
    "\n",
    "    for i in range(10):\n",
    "        if i!=i_sig:\n",
    "            for j in range(30):\n",
    "                Xp = of.signal(key,x,sigma,n1,n2,n3,n4)\n",
    "                X.append(Xp)\n",
    "                y.append(key+10)\n",
    "            \n",
    "    return np.array(X),np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# n_try = 3\n",
    "# n_core = 3\n",
    "# for i in range(1,2):\n",
    "#     X, y = synt_event(i)\n",
    "#     b_time = time.time()   \n",
    "#     out = Parallel(n_jobs=int(n_core)) (delayed(job)(X,y,n_t) for n_t in range(n_try))          \n",
    "#     print \"Finished in\", time.time()-b_time , \"sec\"\n",
    "#     with open(str(i)+'_event.pkl', 'wb') as f:\n",
    "#         pickle.dump(out, f)\n",
    "#     np.save('X_'+str(i)+'_event',X)\n",
    "#     np.save('y_'+str(i)+'_event',y)\n",
    "        \n",
    "# for i in range(1,2):\n",
    "#     X, y = synt_mix(i)\n",
    "#     b_time = time.time()   \n",
    "#     out = Parallel(n_jobs=int(n_core)) (delayed(job)(X,y,n_t) for n_t in range(n_try))          \n",
    "#     print \"Finished in\", time.time()-b_time , \"sec\"\n",
    "#     with open(str(i)+'_mix.pkl', 'wb') as f:\n",
    "#         pickle.dump(out, f)\n",
    "#     np.save('X_'+str(i)+'_mix',X)\n",
    "#     np.save('y_'+str(i)+'_mix',y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUND 0\n",
      "Split level: 1\n",
      "ROUND 0\n",
      "Split level: 1\n",
      "ROUND 0\n",
      "Split level: 1\n",
      "ROUND 0\n",
      "Split level: 1\n",
      "Epoch: 20, cost= 0.155176\n",
      "ROUND 0\n",
      "Split level: 1\n",
      "Epoch: 20, cost= 117.607\n"
     ]
    }
   ],
   "source": [
    "def synt_unbalanced():\n",
    "    train_data = {1:2000,2:2000,3:2000,4:2000,5:50,6:50}\n",
    "    test_data = {1:2000,2:2000,3:2000,4:2000,5:50,6:50,7:50,8:50,9:50,10:50}\n",
    "    sigma = 0.05\n",
    "    n1 = 0.02\n",
    "    n2 = 0.01\n",
    "    n3 = 0.02\n",
    "    n4 = 0.01\n",
    "\n",
    "    n_ftrs = 200\n",
    "    x = np.linspace(0,1,n_ftrs)\n",
    "\n",
    "    X = []\n",
    "    y = []\n",
    "    for key,value in train_data.iteritems():\n",
    "        for _ in range(value):\n",
    "            Xp = of.signal(key,x,sigma,n1,n2,n3,n4)\n",
    "            X.append(Xp)\n",
    "            y.append(key)\n",
    "    X_train = np.array(X)\n",
    "    y_train = np.array(y)\n",
    "    \n",
    "    for key,value in test_data.iteritems():\n",
    "        for _ in range(value):\n",
    "            Xp = of.signal(key,x,sigma,n1,n2,n3,n4)\n",
    "            X.append(Xp)\n",
    "            y.append(key)\n",
    "    X_test = np.array(X)\n",
    "    y_test = np.array(y)\n",
    "    \n",
    "    return X_train,y_train,X_test,y_test \n",
    "\n",
    "def quick_outlier_analysis(X_train,y_train,X_test,y_test,ns):\n",
    "    \n",
    "    out = {}\n",
    "    n_data,n_ftrs = X_train.shape\n",
    "    n_out = ((y_test==7) | (y_test==8) |(y_test==9) |(y_test==10)).sum()\n",
    "    nn_en = [n_ftrs, n_ftrs//2, 2]\n",
    "    nn_de = [2, n_ftrs//2, n_ftrs]\n",
    "    network_architecture = [nn_en,nn_de]\n",
    "    out['n_data'] = n_data\n",
    "    out['n_out'] = n_out\n",
    "\n",
    "    dim_rs ={'AE':'AE','VAE':'VAE', \n",
    "             'PCA':PCA(n_components=2),\n",
    "             'NMF':NMF(n_components=2), \n",
    "             'FastICA':FastICA(n_components=2)}\n",
    "    \n",
    "    for dim_r, value in dim_rs.iteritems():\n",
    "        if dim_r=='VAE' or dim_r=='AE':\n",
    "            dc = of.decomposer(X_train, value, network_architecture, splitter)\n",
    "        else:\n",
    "            dc = of.decomposer_gen(X_train, of.sk_convert(value), splitter)\n",
    "    \n",
    "        for i in range(ns):\n",
    "            print 'ROUND '+str(i)\n",
    "            if dim_r=='VAE' or dim_r=='AE':\n",
    "                dc.split(1,verbose=True,training_epochs=20)\n",
    "            else:\n",
    "                dc.split(1,verbose=True)\n",
    "                \n",
    "            out_ind = outliers(X_test,dc,metrics)\n",
    "            for metric in metrics:\n",
    "                t_out = ((y_test==7) | (y_test==8) |(y_test==9) |(y_test==10))\n",
    "                src = of.score(out_ind[metric][:n_out],t_out)\n",
    "                out['recall_'+dim_r+'_'+metric+'_'+str(i)] = src[n_out-1]\n",
    "                out['auc_'+dim_r+'_'+metric+'_'+str(i)] = roc_auc_score(t_out, of.ind2score(out_ind[metric]))\n",
    "                \n",
    "    for nn in [5,10,35]:\n",
    "        lof = neighbors.LocalOutlierFactor(n_neighbors=nn, contamination=(1.*n_out)/n_data)\n",
    "        lof.fit(X_test)\n",
    "        scores_pred = lof.negative_outlier_factor_\n",
    "        winds = np.argsort(scores_pred)\n",
    "        src = of.score(winds[:n_out],t_out)\n",
    "        out['recall_LOF'+str(nn)] = src[n_out-1]\n",
    "        out['auc_LOF'+str(nn)] = roc_auc_score(t_out, of.ind2score(winds))\n",
    "    \n",
    "    isof = IsolationForest(max_samples='auto', contamination=(1.*n_out)/n_data)\n",
    "    isof.fit(X_train)\n",
    "    scores_pred = isof.decision_function(X_test)\n",
    "    winds = np.argsort(scores_pred)\n",
    "    src = of.score(winds[:n_out],t_out)\n",
    "    out['recall_isof'] = src[n_out-1]\n",
    "    out['auc_isof'] = roc_auc_score(t_out, of.ind2score(winds))\n",
    "    \n",
    "    return out\n",
    "\n",
    "# def job(X,y,n_t):\n",
    "#     return quick_outlier_analysis(X,y,3)\n",
    "\n",
    "X_train,y_train,X_test,y_test = synt_unbalanced()\n",
    "out = quick_outlier_analysis(X_train,y_train,X_test,y_test,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = pklread('../data/syn/train.pkl')\n",
    "event = pklread('../data/syn/event.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 200)\n",
      "(500, 200)\n"
     ]
    }
   ],
   "source": [
    "print train['X'].shape\n",
    "print event['X'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dim_reds = ['AE','VAE','PCA','NMF','FastICA']\n",
    "dim_clrs = ['r','b','g','y','orange']\n",
    "metrics = ['cityblock','L2','L4','expL4','braycurtis',\n",
    "           'canberra','chebyshev','correlation','mahalanobis',\n",
    "           'wL2','wL4','wexpL4']\n",
    "\n",
    "def mean_dic(res,case,num):\n",
    "    vr = []\n",
    "    for i in range(num):\n",
    "        vr.append(res[i][case])\n",
    "    return np.mean(vr),np.std(vr)\n",
    "\n",
    "def analyze_plot(res,sl,out):\n",
    "    lbls = []\n",
    "    values = []\n",
    "    stds = []\n",
    "    clrs = []\n",
    "\n",
    "    for metr in metrics:\n",
    "        for i,drm in enumerate(dim_reds):\n",
    "\n",
    "            lbl = 'auc_'+drm+'_'+metr+'_'+str(sl)\n",
    "            mm,ss = mean_dic(res,lbl,50)\n",
    "            values.append(mm)\n",
    "            stds.append(ss)\n",
    "            clrs.append(dim_clrs[i])\n",
    "            lbls.append(lbl.split('_')[-2])\n",
    "\n",
    "            \n",
    "    for nn in ['5','10','35']:\n",
    "        lbls.append('LOF'+nn)\n",
    "        mm,ss = mean_dic(res,'auc_LOF'+nn,50)\n",
    "        values.append(mm)\n",
    "        stds.append(ss)\n",
    "        clrs.append('c')\n",
    "\n",
    "    lbls.append('i-forest')\n",
    "    mm,ss = mean_dic(res,'auc_isof',50)\n",
    "    values.append(mm)\n",
    "    stds.append(ss)\n",
    "    clrs.append('c')\n",
    "    \n",
    "    # print res[0]['n_out']\n",
    "\n",
    "    fig = plt.figure(figsize=(12, 5))\n",
    "    gs = gridspec.GridSpec(1,1)\n",
    "    ax = fig.add_subplot(gs[0])\n",
    "\n",
    "    w_l = 0.5     # the width of the bars\n",
    "    w_b = 0.74\n",
    "\n",
    "    s0 = 0\n",
    "    s1 = len(lbls)*w_l\n",
    "    s2 = s1+w_b\n",
    "\n",
    "    ind = reduce(np.append,(np.arange(s0,s1,w_l))) \n",
    "    ax.set_xticks(ind + w_l / 2)\n",
    "    ax.set_xticklabels(lbls,rotation='vertical',fontsize=7)\n",
    "    ax.set_ylabel('AUC',fontsize=10)\n",
    "    \n",
    "    p = ax.bar(ind+w_l/4., values, w_l/2, yerr=stds, color=clrs)\n",
    "    \n",
    "    ax.set_ylim(0,1)\n",
    "    ax.grid(True, which='both')\n",
    "    ax.legend((p[0], p[1], p[2], p[3], p[4], p[-1]), ('AE', 'VAE', 'PCA', 'NMF', 'ICA', 'Others'),\n",
    "              bbox_to_anchor=(1.085, 1.022), fontsize=8)\n",
    "    \n",
    "    plt.subplots_adjust(bottom=0.15, top=0.98, left=0.05, right=0.92)\n",
    "    plt.savefig(out+'.jpg',dpi=150)\n",
    "    plt.close()\n",
    "    \n",
    "fils = glob.glob('../results/benchmark/*.pkl')\n",
    "\n",
    "# for fil in fils:\n",
    "#     for sl in range(3):\n",
    "#         res = pklread(fil)\n",
    "#         out = fil.split('/')[-1]\n",
    "#         analyze_plot(res,sl,fil[:-4]+'_'+str(sl))\n",
    "        \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def labeler(lbls):\n",
    "    lbls2 = [None for i in lbls]\n",
    "    for i,s in enumerate(lbls):\n",
    "        s = s.replace('auc_', '')\n",
    "        s = s.replace('Fast', '')\n",
    "#         s = s.replace('LOF5', 'LOF_5') \n",
    "#         s = s.replace('LOF10', 'LOF_10') \n",
    "#         s = s.replace('LOF35', 'LOF_35') \n",
    "        s = s.replace('_', '-')\n",
    "        s = s.replace('cityblock', 'Cityblock')\n",
    "#         s = s.replace('L2', 'L_2')\n",
    "        s = s.replace('expL4', 'exp(L4)') \n",
    "#         s = s.replace('L4', 'L_4')  \n",
    "#         s = s.replace('wL2', 'WL_2')\n",
    "        s = s.replace('wexp(L_4)', 'exp(WL4)') \n",
    "#         s = s.replace('wL4', 'WL_4') \n",
    "        s = s.replace('braycurtis', 'Bray-Curtis')\n",
    "        s = s.replace('canberra', 'Canberra')\n",
    "        s = s.replace('chebyshev', 'Chebyshev')\n",
    "        s = s.replace('correlation', 'Correlation')\n",
    "        s = s.replace('mahalanobis', 'Mahalanobis')            \n",
    "        lbls2[i] = r''+s+''\n",
    "    return lbls2\n",
    "\n",
    "metrics = ['cityblock','L2','L4','expL4','braycurtis',\n",
    "           'canberra','chebyshev','correlation','mahalanobis',\n",
    "           'wL2','wL4','wexpL4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "5\n",
      "10\n",
      "15\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "fils = sorted(glob.glob('../results/benchmark/*.pkl'), key=os.path.getsize)\n",
    "\n",
    "n_mth = 4\n",
    "w_l = 0.5     # the width of the bars\n",
    "w_b = 1.5\n",
    "\n",
    "for nf in range(0,21,5):\n",
    "    print nf\n",
    "    \n",
    "    lbl_p = []\n",
    "    v_p = []\n",
    "    s_p = []\n",
    "    name_p = []\n",
    "    clrs_p = []\n",
    "\n",
    "    for fil in fils[nf:nf+5]:\n",
    "\n",
    "        res = pklread(fil)\n",
    "        lbls = []\n",
    "        values = []\n",
    "        stds = []\n",
    "\n",
    "        name = fil.split('/')[-1]\n",
    "        name_p.append(name[:-4])\n",
    "\n",
    "        for metr in metrics:\n",
    "            for i,drm in enumerate(dim_reds):\n",
    "                for sl in range(3):\n",
    "                    lbl = 'auc_'+drm+'_'+metr+'_'+str(sl)\n",
    "                    lbls.append(lbl)\n",
    "                    mm,ss = mean_dic(res,lbl,50)\n",
    "                    values.append(mm)\n",
    "                    stds.append(ss)\n",
    "\n",
    "        sort_ind = np.argsort(np.array(values))[::-1]\n",
    "        sort_ind = sort_ind[:n_mth]\n",
    "\n",
    "        lbls = np.array(lbls)[sort_ind]\n",
    "        values = np.array(values)[sort_ind]\n",
    "        stds = np.array(stds)[sort_ind]\n",
    "\n",
    "\n",
    "        mmm = 0\n",
    "        for nn in ['5','10','35']:\n",
    "            mm,ss = mean_dic(res,'auc_LOF'+nn,50)\n",
    "            if mm>mmm:\n",
    "                mmm=mm\n",
    "                sss = ss\n",
    "                nnn = nn\n",
    "\n",
    "        lbls = np.append(lbls,'LOF'+nnn)\n",
    "        values = np.append(values,mmm)\n",
    "        stds = np.append(stds,sss)\n",
    "\n",
    "        lbls = np.append(lbls,'i-forest')\n",
    "        mm,ss = mean_dic(res,'auc_isof',50)\n",
    "        values = np.append(values,mm)\n",
    "        stds = np.append(stds,ss)\n",
    "\n",
    "        clrs_p.append(['b']*n_mth+['r','g'])\n",
    "\n",
    "        lbl_p.append(lbls)\n",
    "        v_p.append(values)\n",
    "        s_p.append(stds)\n",
    "\n",
    "    lbl_p = list_flat(lbl_p)\n",
    "    v_p = list_flat(v_p)\n",
    "    s_p = list_flat(s_p)\n",
    "    clrs_p = list_flat(clrs_p)\n",
    "\n",
    "    fig = plt.figure(figsize=(12, 5))\n",
    "    gs = gridspec.GridSpec(1,1)\n",
    "    ax = fig.add_subplot(gs[0])\n",
    "\n",
    "    ind = ind_pos(n_mth+2,5,w_l,w_b)\n",
    "    ax.set_xticks(ind + w_l / 2)\n",
    "    ax.set_xticklabels(labeler(lbl_p),rotation='vertical',fontsize=12)\n",
    "    ax.set_ylabel('AUC',fontsize=15)\n",
    "    plt.yticks(fontsize=12)\n",
    "\n",
    "    for i,name in enumerate(name_p):\n",
    "        ax.text((i+0.5)*(n_mth+1)*w_l+i*w_b-len(name)/12., 1.04, name, fontsize=18)\n",
    "\n",
    "    p = ax.bar(ind+w_l/4., v_p, 2.*w_l/3, yerr=s_p, color=clrs_p\n",
    "          , error_kw=dict(lw=3, capsize=5, capthick=3, ecolor='k'))\n",
    "\n",
    "    ax.grid(True, which='both')\n",
    "    ax.legend((p[0], p[n_mth], p[n_mth+1]), ('MCE', 'LOF', 'i-forest'),\n",
    "              bbox_to_anchor=(1.135, 1.04), fontsize=12)\n",
    "\n",
    "    ax.set_ylim(0,1)\n",
    "\n",
    "    plt.subplots_adjust(bottom=0.35, top=0.92, left=0.06, right=0.89)\n",
    "    plt.savefig('real_'+str(nf)+'.jpg',dpi=300)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fils = sorted(glob.glob('../results/benchmark/*.pkl'), key=os.path.getsize)\n",
    "\n",
    "columns = ['Dataset']+['PCA','ICA','NMF','AE','VAE','LOF','i-forest']\n",
    "n_row = len(fils)\n",
    "index = np.arange(n_row) # array of numbers for the number of samples\n",
    "df = pd.DataFrame(columns=columns, index = index)\n",
    "\n",
    "# lbl_p = []\n",
    "# v_p = []\n",
    "# s_p = []\n",
    "# name_p = []\n",
    "# clrs_p = []\n",
    "\n",
    "for i,fil in enumerate(fils):\n",
    "\n",
    "    res = pklread(fil)\n",
    "\n",
    "    name = fil.split('/')[-1]\n",
    "    df['Dataset'][i] = name[:-4]\n",
    "\n",
    "    for j,drm in enumerate(dim_reds):\n",
    "        mmm = 0\n",
    "        for metr in metrics:\n",
    "            for sl in range(3):\n",
    "                lbl = 'auc_'+drm+'_'+metr+'_'+str(sl)\n",
    "                mm,ss = mean_dic(res,lbl,50)\n",
    "                if mm>mmm:\n",
    "                    mmm=mm\n",
    "                    sss = ss\n",
    "                    nnn = nn  \n",
    "        df[columns[j+1]][i] = tdigit(mmm,sss)\n",
    "\n",
    "#     sort_ind = np.argsort(np.array(values))[::-1]\n",
    "#     sort_ind = sort_ind[:n_mth]\n",
    "\n",
    "#     lbls = np.array(lbls)[sort_ind]\n",
    "#     values = np.array(values)[sort_ind]\n",
    "#     stds = np.array(stds)[sort_ind]\n",
    "\n",
    "\n",
    "    mmm = 0\n",
    "    for nn in ['5','10','35']:\n",
    "        mm,ss = mean_dic(res,'auc_LOF'+nn,50)\n",
    "        if mm>mmm:\n",
    "            mmm=mm\n",
    "            sss = ss\n",
    "            nnn = nn  \n",
    "    df['LOF'][i] = tdigit(mmm,sss)\n",
    "\n",
    "    mm,ss = mean_dic(res,'auc_isof',50)\n",
    "    df['i-forest'][i] = tdigit(mm,ss)\n",
    "\n",
    "\n",
    "\n",
    "# lbl_p = list_flat(lbl_p)\n",
    "# v_p = list_flat(v_p)\n",
    "# s_p = list_flat(s_p)\n",
    "# clrs_p = list_flat(clrs_p)\n",
    "\n",
    "table_gen(df,'real_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../results/synthetic/1_mix_3.pkl\n",
      "../results/synthetic/2_mix_3.pkl\n",
      "../results/synthetic/3_mix_3.pkl\n",
      "../results/synthetic/4_mix_3.pkl\n",
      "../results/synthetic/5_mix_3.pkl\n",
      "../results/synthetic/6_mix_3.pkl\n",
      "../results/synthetic/7_mix_3.pkl\n",
      "../results/synthetic/8_mix_3.pkl\n",
      "../results/synthetic/9_mix_3.pkl\n",
      "../results/synthetic/10_mix_3.pkl\n"
     ]
    }
   ],
   "source": [
    "case = 'mix'\n",
    "n_sig = 10\n",
    "\n",
    "columns = ['DRO']+[str(i+1) for i in range(n_sig)]\n",
    "dmrs = ['PCA','ICA','NMF','AE','VAE','LOF','i-forest']\n",
    "n_row = len(dmrs)\n",
    "index = np.arange(n_row) # array of numbers for the number of samples\n",
    "df = pd.DataFrame(columns=columns, index = index)\n",
    "for i in range(n_row):\n",
    "    df['DRO'][i] = dmrs[i]\n",
    "    \n",
    "for i_sig in range(n_sig):\n",
    "    sig = i_sig+1\n",
    "    fils = glob.glob('../results/synthetic/'+str(sig)+'_'+'*'+case+'_3.pkl')\n",
    "\n",
    "    for fil in fils:\n",
    "        print fil\n",
    "        res = pklread(fil)\n",
    "\n",
    "    for i,drm in enumerate(dim_reds):  \n",
    "        m_max = 0\n",
    "        for metr in metrics:\n",
    "            for sl in range(3):\n",
    "                lbl = 'auc_'+drm+'_'+metr+'_'+str(sl)\n",
    "                mm,ss = mean_dic(res,lbl,50)\n",
    "                if mm>m_max:\n",
    "                    m_max = mm\n",
    "                    s_max = ss\n",
    "                    lb_max = lbl\n",
    "\n",
    "\n",
    "        df[str(sig)][i] = tdigit(m_max,s_max)\n",
    "\n",
    "    mmm = 0\n",
    "    for nn in ['5','10','35']:\n",
    "        mm,ss = mean_dic(res,'auc_LOF'+nn,50)\n",
    "        if mm>mmm:\n",
    "            mmm=mm\n",
    "            nnn = nn\n",
    "            sss = ss\n",
    "\n",
    "    df[str(sig)][5] = tdigit(mmm,sss)\n",
    "\n",
    "    mm,ss = mean_dic(res,'auc_isof',50)\n",
    "    df[str(sig)][6] = tdigit(mm,ss)\n",
    "    \n",
    "table_gen(df,case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def table_gen(df,name):\n",
    "    import subprocess\n",
    "    tab = df.to_latex(escape=False, index=False)\n",
    "    tab = r'''\\documentclass[border=0.5in]{standalone}\n",
    "\\usepackage{booktabs}\n",
    "\\usepackage{pdflscape}\n",
    "\\usepackage[a4paper,bindingoffset=0.2in,%\n",
    "        left=0.25in,right=0.25in,top=1in,bottom=1in,%\n",
    "        footskip=.25in]{geometry}\n",
    "\\begin{document}\n",
    "\\begin{centering}\n",
    "\\pagenumbering{gobble}\n",
    "\\oddsidemargin = 0pt\n",
    "\\hoffset = -0.25in\n",
    "\\topmargin = 1pt\n",
    "\\headheight = 0pt\n",
    "\\headsep = 0pt\n",
    "    '''+\\\n",
    "    tab+'''\n",
    "\\end{centering}\n",
    "\\end{document}\n",
    "    '''\n",
    "    f = open(name+'.tex','w') \n",
    "    f.write(tab) \n",
    "    f.close() \n",
    "    subprocess.call(['xelatex', name+'.tex'])\n",
    "    subprocess.call(['rm', name+'.aux'])\n",
    "    subprocess.call(['rm', name+'.log'])\n",
    "#     subprocess.call(['rm', name+'.tex'])\n",
    "\n",
    "def tdigit(x,e):\n",
    "    if e<1e-2:\n",
    "        return '${:.2g}$'.format(x)\n",
    "    else:\n",
    "        return '${:.2g}\\\\pm{:.1g}$'.format(x,e)\n",
    "\n",
    "# supervised\n",
    "metrics_sup = ['cityblock','L2','L4','expL4','braycurtis',\n",
    "           'chebyshev','correlation','mahalanobis']\n",
    "\n",
    "res = pklread('../results/synthetic/supervised_2.pkl')\n",
    "\n",
    "columns = ['DRO']+metrics_sup\n",
    "dmrs = ['PCA','ICA','NMF','AE','VAE','LOF','i-forest']\n",
    "n_row = len(dmrs)\n",
    "index = np.arange(n_row) # array of numbers for the number of samples\n",
    "df = pd.DataFrame(columns=columns, index = index)\n",
    "for i in range(n_row):\n",
    "    df['DRO'][i] = dmrs[i]\n",
    "    \n",
    "for metr in metrics_sup:\n",
    "    for i,drm in enumerate(dim_reds):\n",
    "        m_max=0\n",
    "        for sl in range(3):\n",
    "            lbl = 'auc_'+drm+'_'+metr+'_'+str(sl)\n",
    "            mm,ss = mean_dic(res,lbl,50)\n",
    "            if mm>m_max:\n",
    "                m_max = mm\n",
    "                s_max = ss\n",
    "            \n",
    "        df[metr][i] = tdigit(m_max,s_max)\n",
    "\n",
    "mmm = 0\n",
    "for nn in ['5','10','35']:\n",
    "    mm,ss = mean_dic(res,'auc_LOF'+nn,50)\n",
    "    if mm>mmm:\n",
    "        mmm=mm\n",
    "        nnn = nn\n",
    "        sss = ss\n",
    "    \n",
    "df['cityblock'][n_row-2] = tdigit(mmm,sss)\n",
    "\n",
    "mm,ss = mean_dic(res,'auc_isof',50)\n",
    "df['cityblock'][n_row-1] = tdigit(mm,ss)\n",
    "\n",
    "table_gen(df,'supervised')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def ind_pos(nl,nc,w_l,w_b):\n",
    "    out = []\n",
    "    for i in range(nc):\n",
    "        for j in range(nl):\n",
    "            out.append(j*w_l+i*(nl-1)*w_l+i*w_b)\n",
    "    return np.array(out)\n",
    "\n",
    "def list_flat(lst):\n",
    "    return np.array(lst).reshape(-1)\n",
    "\n",
    "def ind2score(oi):\n",
    "    num = oi.shape[0]\n",
    "    score = np.zeros(num)\n",
    "    score[oi[::-1]] = np.linspace(0,1,num)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0. ,  0.1,  0.2,  0.3,  0.4])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
